import streamlit as st
import pandas as pd
import numpy as np
import json
import io

# Import the refactored processing functions
try:
    from processing.data_processing import process_building_data
    from processing.timeseries_processing import process_timeseries_data
    from processing.assignment_generation import generate_assignments
except ImportError:
    st.error("Could not import processing modules. Ensure this script is in the 'mimic' directory and your processing scripts are inside a 'processing' sub-folder.")
    st.stop()

# --- Page Configuration ---
st.set_page_config(
    page_title="Energy Community Data Pipeline",
    page_icon="üèôÔ∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- Default Scenario Configurations ---
DEFAULT_SOLAR_SCENARIOS = {
    "default": {"penetration_rate": 0.10, "types": [{"name": "default_pv_small", "kWp_range": [2.0, 4.0], "weight": 0.6}, {"name": "default_pv_medium", "kWp_range": [4.1, 8.0], "weight": 0.4}]},
    "residential": {"penetration_rate": 0.25, "types": [{"name": "res_pv_standard", "kWp_range": [3.0, 7.0], "weight": 0.7}, {"name": "res_pv_large", "kWp_range": [7.1, 15.0], "weight": 0.3}]},
    "non_residential": {"penetration_rate": 0.40, "types": [{"name": "comm_pv_medium", "kWp_range": [10.0, 50.0], "weight": 0.5}, {"name": "comm_pv_large", "kWp_range": [50.1, 250.0], "weight": 0.3}, {"name": "comm_pv_xlarge", "kWp_range": [250.1, 1000.0], "weight": 0.2}]}
}
DEFAULT_BATTERY_SCENARIOS = {
    "default": {"penetration_rate_if_solar": 0.15, "overall_penetration_rate": 0.02, "types": [{"name": "default_batt_small", "kWh_range": [4.0, 8.0], "kW_range": [2.0, 4.0], "weight": 1.0}]},
    "residential": {"penetration_rate_if_solar": 0.30, "overall_penetration_rate": 0.05, "types": [{"name": "res_batt_daily", "kWh_range": [5.0, 15.0], "kW_range": [2.5, 7.0], "weight": 0.8}, {"name": "res_batt_backup", "kWh_range": [15.1, 30.0], "kW_range": [5.0, 10.0], "weight": 0.2}]},
    "non_residential": {"penetration_rate_if_solar": 0.50, "overall_penetration_rate": 0.10, "types": [{"name": "comm_batt_demand_peak", "kWh_range": [20.0, 100.0], "kW_range": [10.0, 50.0], "weight": 0.6}, {"name": "comm_batt_storage_large", "kWh_range": [100.1, 500.0], "kW_range": [50.1, 200.0], "weight": 0.4}]}
}

# --- Helper Functions ---
@st.cache_data(ttl=3600) # Cache loaded data for 1 hour
def load_csv_data_from_bytes(uploaded_file_bytes, filename="uploaded_file"):
    if uploaded_file_bytes is not None:
        try:
            return pd.read_csv(io.BytesIO(uploaded_file_bytes))
        except Exception as e:
            st.error(f"Error reading CSV ({filename}): {e}")
            return None
    return None

def df_to_csv_bytes(df):
    output = io.StringIO()
    df.to_csv(output, index=False)
    return output.getvalue().encode('utf-8')

# --- Initialize Session State ---
# For storing data between steps and UI states
if 'raw_buildings_bytes' not in st.session_state: st.session_state.raw_buildings_bytes = None
if 'raw_timeseries_bytes' not in st.session_state: st.session_state.raw_timeseries_bytes = None
if 'processed_buildings_uploaded_bytes' not in st.session_state: st.session_state.processed_buildings_uploaded_bytes = None

# DataFrames generated by steps
if 'df_buildings_processed' not in st.session_state: st.session_state.df_buildings_processed = None
if 'df_timeseries_processed' not in st.session_state: st.session_state.df_timeseries_processed = None
if 'df_assignments' not in st.session_state: st.session_state.df_assignments = None
if 'df_buildings_with_lines' not in st.session_state: st.session_state.df_buildings_with_lines = None

# Step completion flags
if 'step1_complete_internal' not in st.session_state: st.session_state.step1_complete_internal = False # True if Step 1 run in this session
if 'processed_buildings_available' not in st.session_state: st.session_state.processed_buildings_available = False # True if Step 1 run OR uploaded
if 'step2_complete' not in st.session_state: st.session_state.step2_complete = False
if 'step3_complete' not in st.session_state: st.session_state.step3_complete = False

if 'status_message' not in st.session_state: st.session_state.status_message = ""
if 'status_type' not in st.session_state: st.session_state.status_type = "info"


# --- Main App UI ---
st.title("üèôÔ∏è Energy Community Data Processing Pipeline")
st.markdown("An interactive tool to process building and time series data for energy system modeling.")

# --- Sidebar for Configuration and Control ---
with st.sidebar:
    st.header("‚öôÔ∏è Configuration & Inputs")

    # 1. File Upload
    st.subheader("1. Upload Data Files")
    raw_buildings_uploader = st.file_uploader(
        "Upload Raw Extracted Buildings CSV (for Step 1)", 
        type="csv", key="raw_buildings_uploader",
        help="Needed if you want to run Step 1."
    )
    raw_timeseries_uploader = st.file_uploader(
        "Upload Raw Time Series CSV (for Step 2)", 
        type="csv", key="raw_timeseries_uploader",
        help="Needed if you want to run Step 2."
    )
    st.markdown("---")
    processed_buildings_uploader = st.file_uploader(
        "Upload Processed Buildings CSV (Optional - to skip Step 1)", 
        type="csv", key="processed_buildings_uploader",
        help="Upload this if you have already processed building data and want to start from Step 2 or 3."
    )

    # Store uploaded file bytes in session state immediately
    if raw_buildings_uploader is not None:
        st.session_state.raw_buildings_bytes = raw_buildings_uploader.getvalue()
    if raw_timeseries_uploader is not None:
        st.session_state.raw_timeseries_bytes = raw_timeseries_uploader.getvalue()
    if processed_buildings_uploader is not None:
        st.session_state.processed_buildings_uploaded_bytes = processed_buildings_uploader.getvalue()
        st.session_state.processed_buildings_available = True # Mark as available
        st.session_state.step1_complete_internal = False # If uploading, internal step 1 wasn't run
        st.session_state.df_buildings_processed = None # Clear any internally generated one
        st.info("Uploaded processed buildings data will be used for Steps 2 & 3.")
    elif st.session_state.step1_complete_internal: # If step 1 was run internally
        st.session_state.processed_buildings_available = True
    else: # No processed buildings available yet
        st.session_state.processed_buildings_available = False


    # 2. Assignment Configuration
    st.subheader("2. Assignment Configuration")
    num_lines_for_assignment = st.number_input("Number of Energy Lines/Clusters", min_value=1, value=6, key="num_lines")

    # 3. Scenario Configuration - User Friendly Widgets
    st.subheader("3. Scenario Configuration")
    current_solar_scenarios = {}
    current_battery_scenarios = {}
    # (Scenario UI code from previous version - kept concise here for brevity, assume it's the same)
    with st.expander("‚òÄÔ∏è Solar Scenarios", expanded=False): # Default to collapsed
        for bldg_func_key, default_scenario_data in DEFAULT_SOLAR_SCENARIOS.items():
            current_solar_scenarios.setdefault(bldg_func_key, {})
            current_solar_scenarios[bldg_func_key].setdefault('types', [])
            with st.container():
                st.markdown(f"**{bldg_func_key.capitalize()} Buildings**")
                pen_rate = st.slider(f"Penetration Rate##solar_pen_{bldg_func_key}", 0.0, 1.0, float(default_scenario_data.get("penetration_rate", 0.1)), 0.01)
                current_solar_scenarios[bldg_func_key]['penetration_rate'] = pen_rate
                for i, type_data in enumerate(default_scenario_data.get("types", [])):
                    st.markdown(f"*{type_data.get('name', 'Unnamed')}*")
                    cols = st.columns([2,2,1])
                    kwp_min = cols[0].number_input(f"kWp Min##solar_kwp_min_{bldg_func_key}_{i}", value=float(type_data.get("kWp_range", [0,0])[0]), step=0.1, format="%.1f")
                    kwp_max = cols[1].number_input(f"kWp Max##solar_kwp_max_{bldg_func_key}_{i}", value=float(type_data.get("kWp_range", [0,0])[1]), step=0.1, format="%.1f")
                    weight = cols[2].number_input(f"Weight##solar_w_{bldg_func_key}_{i}", value=float(type_data.get("weight", 1.0)), min_value=0.0, step=0.1, format="%.1f")
                    current_solar_scenarios[bldg_func_key]['types'].append({"name": type_data.get('name'), "kWp_range": [kwp_min, kwp_max], "weight": weight})
                st.divider()

    with st.expander("üîã Battery Scenarios", expanded=False): # Default to collapsed
        for bldg_func_key, default_scenario_data in DEFAULT_BATTERY_SCENARIOS.items():
            current_battery_scenarios.setdefault(bldg_func_key, {})
            current_battery_scenarios[bldg_func_key].setdefault('types', [])
            with st.container():
                st.markdown(f"**{bldg_func_key.capitalize()} Buildings**")
                pen_rate_solar = st.slider(f"Penetration if Solar##batt_pen_solar_{bldg_func_key}", 0.0, 1.0, float(default_scenario_data.get("penetration_rate_if_solar", 0.15)), 0.01)
                pen_rate_overall = st.slider(f"Overall Penetration##batt_pen_overall_{bldg_func_key}", 0.0, 1.0, float(default_scenario_data.get("overall_penetration_rate", 0.02)), 0.01)
                current_battery_scenarios[bldg_func_key]['penetration_rate_if_solar'] = pen_rate_solar
                current_battery_scenarios[bldg_func_key]['overall_penetration_rate'] = pen_rate_overall
                for i, type_data in enumerate(default_scenario_data.get("types", [])):
                    st.markdown(f"*{type_data.get('name', 'Unnamed')}*")
                    cols_kwh = st.columns(2); kwh_min = cols_kwh[0].number_input(f"kWh Min##batt_kwh_min_{bldg_func_key}_{i}", value=float(type_data.get("kWh_range", [0,0])[0]), step=0.1, format="%.1f"); kwh_max = cols_kwh[1].number_input(f"kWh Max##batt_kwh_max_{bldg_func_key}_{i}", value=float(type_data.get("kWh_range", [0,0])[1]), step=0.1, format="%.1f")
                    cols_kw_weight = st.columns([1,1,1]); kw_min = cols_kw_weight[0].number_input(f"kW Min##batt_kw_min_{bldg_func_key}_{i}", value=float(type_data.get("kW_range", [0,0])[0]), step=0.1, format="%.1f"); kw_max = cols_kw_weight[1].number_input(f"kW Max##batt_kw_max_{bldg_func_key}_{i}", value=float(type_data.get("kW_range", [0,0])[1]), step=0.1, format="%.1f"); batt_weight = cols_kw_weight[2].number_input(f"Weight##batt_w_{bldg_func_key}_{i}", value=float(type_data.get("weight", 1.0)), min_value=0.0, step=0.1, format="%.1f")
                    current_battery_scenarios[bldg_func_key]['types'].append({"name": type_data.get('name'), "kWh_range": [kwh_min, kwh_max], "kW_range": [kw_min, kw_max], "weight": batt_weight})
                st.divider()

    # 4. Execution Buttons
    st.subheader("4. Run Pipeline Steps")
    
    # --- Step 1 Button ---
    if st.button("‚ñ∂Ô∏è Run Step 1: Process Buildings", use_container_width=True, key="run_step1"):
        if st.session_state.raw_buildings_bytes is None:
            st.session_state.status_message = "Upload Raw Extracted Buildings CSV for Step 1."
            st.session_state.status_type = "error"
        else:
            df_buildings_raw = load_csv_data_from_bytes(st.session_state.raw_buildings_bytes, "Raw Buildings CSV")
            if df_buildings_raw is not None:
                with st.spinner("Running Step 1..."):
                    try:
                        st.session_state.df_buildings_processed = process_building_data(
                            buildings_df=df_buildings_raw.copy(),
                            solar_scenarios=current_solar_scenarios,
                            battery_scenarios=current_battery_scenarios
                        )
                        st.session_state.step1_complete_internal = True
                        st.session_state.processed_buildings_available = True
                        st.session_state.processed_buildings_uploaded_bytes = None # Clear if Step 1 is run
                        # Reset subsequent steps
                        st.session_state.step2_complete = False; st.session_state.df_timeseries_processed = None
                        st.session_state.step3_complete = False; st.session_state.df_assignments = None; st.session_state.df_buildings_with_lines = None
                        st.session_state.status_message = "‚úÖ Step 1: Building data processed!"
                        st.session_state.status_type = "success"
                    except Exception as e:
                        st.session_state.status_message = f"Error in Step 1: {e}"; st.session_state.status_type = "error"; st.exception(e)
            else:
                st.session_state.status_message = "Could not load Raw Buildings CSV for Step 1."; st.session_state.status_type = "error"

    # --- Step 2 Button ---
    step2_disabled_reason = ""
    if st.session_state.raw_timeseries_bytes is None: step2_disabled_reason = "Upload Raw Time Series CSV."
    elif not st.session_state.processed_buildings_available: step2_disabled_reason = "Run Step 1 or Upload Processed Buildings CSV."
    
    if st.button("‚ñ∂Ô∏è Run Step 2: Process Time Series", use_container_width=True, key="run_step2", disabled=bool(step2_disabled_reason)):
        df_input_buildings_for_step2 = None
        source_msg_s2 = ""
        if st.session_state.processed_buildings_uploaded_bytes is not None:
            df_input_buildings_for_step2 = load_csv_data_from_bytes(st.session_state.processed_buildings_uploaded_bytes, "Uploaded Processed Buildings")
            source_msg_s2 = "Using uploaded processed buildings data for Step 2."
        elif st.session_state.step1_complete_internal and st.session_state.df_buildings_processed is not None:
            df_input_buildings_for_step2 = st.session_state.df_buildings_processed
            source_msg_s2 = "Using Step 1 output for Step 2."
        
        if df_input_buildings_for_step2 is None:
            st.session_state.status_message = "Processed building data not available for Step 2."; st.session_state.status_type = "error"
        else:
            df_timeseries_raw = load_csv_data_from_bytes(st.session_state.raw_timeseries_bytes, "Raw Time Series CSV")
            if df_timeseries_raw is not None:
                st.info(source_msg_s2)
                with st.spinner("Running Step 2..."):
                    try:
                        st.session_state.df_timeseries_processed = process_timeseries_data(
                            ts_df=df_timeseries_raw.copy(),
                            buildings_df=df_input_buildings_for_step2.copy()
                        )
                        st.session_state.step2_complete = True
                        st.session_state.step3_complete = False; st.session_state.df_assignments = None; st.session_state.df_buildings_with_lines = None # Reset step 3
                        st.session_state.status_message = "‚úÖ Step 2: Time series data processed!"
                        st.session_state.status_type = "success"
                    except Exception as e:
                        st.session_state.status_message = f"Error in Step 2: {e}"; st.session_state.status_type = "error"; st.exception(e)
            else:
                st.session_state.status_message = "Could not load Raw Time Series CSV for Step 2."; st.session_state.status_type = "error"
    elif step2_disabled_reason:
        st.caption(f"Step 2 disabled: {step2_disabled_reason}")


    # --- Step 3 Button ---
    step3_disabled_reason = ""
    if not st.session_state.processed_buildings_available: step3_disabled_reason = "Run Step 1 or Upload Processed Buildings CSV."

    if st.button("‚ñ∂Ô∏è Run Step 3: Generate Assignments", use_container_width=True, key="run_step3", disabled=bool(step3_disabled_reason)):
        df_input_buildings_for_step3 = None
        source_msg_s3 = ""
        if st.session_state.processed_buildings_uploaded_bytes is not None:
            df_input_buildings_for_step3 = load_csv_data_from_bytes(st.session_state.processed_buildings_uploaded_bytes, "Uploaded Processed Buildings")
            source_msg_s3 = "Using uploaded processed buildings data for Step 3."
        elif st.session_state.step1_complete_internal and st.session_state.df_buildings_processed is not None:
            df_input_buildings_for_step3 = st.session_state.df_buildings_processed
            source_msg_s3 = "Using Step 1 output for Step 3."

        if df_input_buildings_for_step3 is None:
            st.session_state.status_message = "Processed building data not available for Step 3."; st.session_state.status_type = "error"
        else:
            st.info(source_msg_s3)
            with st.spinner("Running Step 3..."):
                try:
                    assignments_df, buildings_with_lines_df = generate_assignments(
                        buildings_df=df_input_buildings_for_step3.copy(),
                        num_lines=num_lines_for_assignment
                    )
                    st.session_state.df_assignments = assignments_df
                    st.session_state.df_buildings_with_lines = buildings_with_lines_df
                    st.session_state.step3_complete = True
                    st.session_state.status_message = "‚úÖ Step 3: Assignments generated!"
                    st.session_state.status_type = "success"
                except Exception as e:
                    st.session_state.status_message = f"Error in Step 3: {e}"; st.session_state.status_type = "error"; st.exception(e)
    elif step3_disabled_reason:
        st.caption(f"Step 3 disabled: {step3_disabled_reason}")

    # --- Run All Button ---
    if st.button("üöÄ Run All Steps (from raw data)", type="primary", use_container_width=True, key="run_all"):
        if st.session_state.raw_buildings_bytes is None or st.session_state.raw_timeseries_bytes is None:
            st.session_state.status_message = "Upload both Raw Buildings and Raw Time Series CSVs to run all steps."
            st.session_state.status_type = "error"
        else:
            df_buildings_raw = load_csv_data_from_bytes(st.session_state.raw_buildings_bytes, "Raw Buildings CSV")
            df_timeseries_raw = load_csv_data_from_bytes(st.session_state.raw_timeseries_bytes, "Raw Time Series CSV")

            if df_buildings_raw is not None and df_timeseries_raw is not None:
                st.session_state.status_message = "Pipeline started (All Steps)..."; st.session_state.status_type = "info"
                progress_bar = st.progress(0)
                try:
                    # Step 1
                    st.session_state.status_message = "Running Step 1..."
                    st.session_state.df_buildings_processed = process_building_data(df_buildings_raw.copy(), current_solar_scenarios, current_battery_scenarios)
                    st.session_state.step1_complete_internal = True; st.session_state.processed_buildings_available = True
                    st.session_state.processed_buildings_uploaded_bytes = None # Ensure internal result is used
                    progress_bar.progress(33)

                    # Step 2
                    st.session_state.status_message = "Running Step 2..."
                    st.session_state.df_timeseries_processed = process_timeseries_data(df_timeseries_raw.copy(), st.session_state.df_buildings_processed.copy())
                    st.session_state.step2_complete = True
                    progress_bar.progress(66)

                    # Step 3
                    st.session_state.status_message = "Running Step 3..."
                    st.session_state.df_assignments, st.session_state.df_buildings_with_lines = generate_assignments(st.session_state.df_buildings_processed.copy(), num_lines_for_assignment)
                    st.session_state.step3_complete = True
                    progress_bar.progress(100)
                    st.session_state.status_message = "‚úÖ All steps completed successfully!"; st.session_state.status_type = "success"
                except Exception as e:
                    st.session_state.status_message = f"Error during 'Run All Steps': {e}"; st.session_state.status_type = "error"; st.exception(e)
            else:
                st.session_state.status_message = "Could not load one or both raw CSV files for 'Run All Steps'."; st.session_state.status_type = "error"

# --- Main Panel for Status and Results ---
if st.session_state.status_message:
    if st.session_state.status_type == "success": st.success(st.session_state.status_message)
    elif st.session_state.status_type == "error": st.error(st.session_state.status_message)
    elif st.session_state.status_type == "warning": st.warning(st.session_state.status_message)
    else: st.info(st.session_state.status_message)

st.header("üìä Results")
results_available_display = False
tabs_to_create = []

if st.session_state.df_buildings_processed is not None or (st.session_state.processed_buildings_uploaded_bytes and st.session_state.processed_buildings_available):
    tabs_to_create.append("Processed Buildings")
if st.session_state.df_timeseries_processed is not None:
    tabs_to_create.append("Processed Time Series")
if st.session_state.df_assignments is not None and st.session_state.df_buildings_with_lines is not None:
    tabs_to_create.append("Assignments & Map")

if not tabs_to_create: tabs_to_create.append("No Results Yet")
tabs = st.tabs(tabs_to_create)
tab_idx = 0

if "Processed Buildings" in tabs_to_create:
    with tabs[tab_idx]:
        st.subheader("Processed Building Data")
        df_to_display_step1 = None
        if st.session_state.processed_buildings_uploaded_bytes and st.session_state.processed_buildings_available:
            df_to_display_step1 = load_csv_data_from_bytes(st.session_state.processed_buildings_uploaded_bytes, "Uploaded Processed Buildings")
            if df_to_display_step1 is not None: st.caption("Displaying: Uploaded Processed Buildings Data")
        elif st.session_state.df_buildings_processed is not None:
            df_to_display_step1 = st.session_state.df_buildings_processed
            if df_to_display_step1 is not None: st.caption("Displaying: Output from Step 1 run in this session")
        
        if df_to_display_step1 is not None:
            st.dataframe(df_to_display_step1)
            st.download_button("‚¨áÔ∏è Download Processed Buildings", df_to_csv_bytes(df_to_display_step1), 'buildings_processed.csv', 'text/csv', use_container_width=True)
            results_available_display = True
        else:
            st.info("No processed building data to display. Run Step 1 or upload a processed file.")
    tab_idx +=1

if "Processed Time Series" in tabs_to_create:
    with tabs[tab_idx]:
        st.subheader("Processed Time Series Data")
        st.dataframe(st.session_state.df_timeseries_processed)
        st.download_button("‚¨áÔ∏è Download Time Series", df_to_csv_bytes(st.session_state.df_timeseries_processed), 'time_series_processed.csv', 'text/csv', use_container_width=True)
        results_available_display = True
    tab_idx +=1

if "Assignments & Map" in tabs_to_create:
    with tabs[tab_idx]:
        st.subheader("Building Assignments")
        st.dataframe(st.session_state.df_assignments)
        st.download_button("‚¨áÔ∏è Download Assignments", df_to_csv_bytes(st.session_state.df_assignments), 'building_assignments.csv', 'text/csv', use_container_width=True)
        
        st.subheader("Buildings with Line Assignments & Map")
        st.dataframe(st.session_state.df_buildings_with_lines)
        st.download_button("‚¨áÔ∏è Download Buildings with Lines", df_to_csv_bytes(st.session_state.df_buildings_with_lines), 'buildings_with_lines.csv', 'text/csv', use_container_width=True)

        if not st.session_state.df_buildings_with_lines.empty and 'lat' in st.session_state.df_buildings_with_lines.columns:
            map_df = st.session_state.df_buildings_with_lines[['lat', 'lon', 'line_id']].copy()
            map_df.dropna(subset=['lat', 'lon'], inplace=True)
            if not map_df.empty:
                unique_lines = map_df['line_id'].unique(); palette = ["#FF4B4B", "#4B7BFF", "#4BFF7B", "#FFFF4B", "#FF4BFF", "#4BFFFF", "#FFA500", "#8A2BE2"]
                color_map = {line: palette[i % len(palette)] for i, line in enumerate(unique_lines)}
                map_df['color'] = map_df['line_id'].map(color_map)
                st.map(map_df, latitude='lat', longitude='lon', color='color', size=50)
        results_available_display = True
    tab_idx +=1

if not results_available_display and "No Results Yet" in tabs_to_create:
    with tabs[tab_idx]:
        st.info("Upload files and run pipeline steps from the sidebar to see results here.")

